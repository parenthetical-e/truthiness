# AUTOGENERATED! DO NOT EDIT! File to edit: gym.ipynb (unless otherwise specified).

__all__ = ['ShameGame1', 'PlainGame1']

# Cell
import numpy as np
import gym

from copy import deepcopy
from gym import spaces
from gym.utils import seeding
from itertools import cycle

from .game import create_maze
from .game import shame_game
from .game import plain_game
from .game import available_moves
from .game import random_move

# Gym is annoying these days...
import warnings
warnings.filterwarnings("ignore")

# Cell
class ShameGame1(gym.Env):
    """A one-sided game of learning and shame"""
    def __init__(self, maze=None, sigma=0.5, shame=0.5, max_steps=10):
        self.maze = maze
        self.n = self.maze.shape[0]
        self.max_steps = max_steps

        self.sigma = sigma
        self.shame = shame

        self.reset()


    def step(self, move):
        if self.count > self.max_steps:
            raise ValueError(f"env exceeded max_steps ({self.count})")

        # Shuffle state, and generate returns
        x, y = move
        reward = deepcopy((self.E[x,y], self.Q[x,y]))
        state = move

        # Values are only found once
        self.E[x,y] = 0
        self.Q[x,y] = 0
        self.move_history.append(move)

        # Limit game length
        self.count += 1
        if self.count >= self.max_steps:
            self.done = True

        return state, reward, self.done, {}


    def reset(self):
        # reinit
        self.count = 0
        self.done = False
        self.move_history = []

        # Generate new
        self.x, self.y = random_move(self.maze)
        self.E, self.Q = shame_game(
            self.n, sigma=self.sigma, shame=self.shame, maze=self.maze)

        return self.x, self.y


    def moves(self, x, y):
        # Get all the moves then filter for moves that
        # have already been played
        candidates = available_moves(x, y, self.maze)

        available = []
        for a in candidates:
            if a not in self.move_history:
                available.append(a)

        return available


    def render(self, mode='human', close=False):
        pass

# Cell
class PlainGame1(gym.Env):
    """A one-sided game of learning and consequences"""
    def __init__(self, maze=None, sigma=0.5, max_steps=10):
        self.maze = maze
        self.n = self.maze.shape[0]
        self.max_steps = max_steps

        self.sigma = sigma

        self.reset()


    def step(self, move):
        if self.count > self.max_steps:
            raise ValueError(f"env exceeded max_steps ({self.count})")

        # Shuffle state, and generate returns
        x, y = move
        reward = deepcopy((self.E[x,y], self.Q[x,y]))
        state = move

        # Values are only found once
        self.E[x,y] = 0
        self.Q[x,y] = 0
        self.move_history.append(move)

        # Limit game length
        self.count += 1
        if self.count >= self.max_steps:
            self.done = True

        return state, reward, self.done, {}


    def reset(self):
        # reinit
        self.count = 0
        self.done = False
        self.move_history = []

        # Generate new
        self.x, self.y = random_move(self.maze)
        self.E, self.Q = plain_game(
            self.n, sigma=self.sigma, maze=self.maze)

        return self.x, self.y


    def moves(self, x, y):
        # Get all the moves then filter for moves that
        # have already been played
        candidates = available_moves(x, y, self.maze)

        available = []
        for a in candidates:
            if a not in self.move_history:
                available.append(a)

        return available


    def render(self, mode='human', close=False):
        pass