{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gym\n",
    "> A `Gym` enviroment for teaching truth and conseqences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from copy import deepcopy\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "from itertools import cycle\n",
    "\n",
    "from truthiness.game import create_maze\n",
    "from truthiness.game import shame_game\n",
    "from truthiness.game import plain_game\n",
    "from truthiness.game import available_moves\n",
    "from truthiness.game import random_move\n",
    "\n",
    "# Gym is annoying these days...\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the shame game env\n",
    "The details of this game are described in the `boards` file. This module exists only to put the games described there into a [gym](https://github.com/openai/gym) environment, and then do some simple testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ShameGame1(gym.Env):\n",
    "    \"\"\"A one-sided game of learning and shame\"\"\"\n",
    "    def __init__(self, maze=None, sigma=0.5, shame=0.5, max_steps=10):\n",
    "        self.maze = maze\n",
    "        self.n = self.maze.shape[0]\n",
    "        self.max_steps = max_steps\n",
    "        \n",
    "        self.sigma = sigma\n",
    "        self.shame = shame\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    \n",
    "    def step(self, move):\n",
    "        if self.count > self.max_steps:\n",
    "            raise ValueError(f\"env exceeded max_steps ({self.count})\")\n",
    "\n",
    "        # Shuffle state, and generate returns\n",
    "        x, y = move\n",
    "        reward = deepcopy((self.E[x,y], self.Q[x,y]))\n",
    "        state = move\n",
    "        \n",
    "        # Values are only found once\n",
    "        self.E[x,y] = 0\n",
    "        self.Q[x,y] = 0\n",
    "        self.move_history.append(move)\n",
    "        \n",
    "        # Limit game length\n",
    "        self.count += 1\n",
    "        if self.count >= self.max_steps:\n",
    "            self.done = True\n",
    "            \n",
    "        return state, reward, self.done, {}\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        # reinit\n",
    "        self.count = 0\n",
    "        self.done = False\n",
    "        self.move_history = []\n",
    "        \n",
    "        # Generate new  \n",
    "        self.x, self.y = random_move(self.maze)\n",
    "        self.E, self.Q = shame_game(\n",
    "            self.n, sigma=self.sigma, shame=self.shame, maze=self.maze)\n",
    "        \n",
    "        return self.x, self.y\n",
    "\n",
    "    \n",
    "    def moves(self, x, y):\n",
    "        # Get all the moves then filter for moves that\n",
    "        # have already been played\n",
    "        candidates = available_moves(x, y, self.maze)\n",
    "\n",
    "        available = []\n",
    "        for a in candidates:\n",
    "            if a not in self.move_history:\n",
    "                available.append(a)\n",
    "                \n",
    "        return available\n",
    "    \n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example of random play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = create_maze(8, k=5, t=10)\n",
    "env = ShameGame1(maze=maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) (0.20821054494816685, 0.10410527247408342) False\n",
      "(2, 0) (0.12515856302413955, 0.06257928151206978) False\n",
      "(2, 4) (0.10364199029348727, 0.05182099514674363) False\n",
      "(4, 4) (0.4097303554202366, 0.2048651777101183) False\n",
      "(0, 4) (0.18101699420430697, 0.09050849710215349) False\n",
      "(0, 6) (0.11923470792047508, 0.05961735396023754) False\n",
      "(0, 1) (0.5547232065516375, 0.27736160327581877) False\n",
      "(0, 5) (0.39338525493690435, 0.19669262746845217) False\n",
      "(1, 5) (0.24315680274740076, 0.12157840137370038) False\n",
      "(2, 5) (0.2797129824166282, 0.1398564912083141) True\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "x, y = env.reset()\n",
    "\n",
    "moves = [(x, y)]\n",
    "while not done:\n",
    "    available = env.moves(x, y)    \n",
    "    i = np.random.randint(0, len(available))\n",
    "    x, y = available[i]\n",
    "    state, reward, done, _ = env.step((x, y))\n",
    "    moves.append((x, y))\n",
    "    \n",
    "    print(state, reward, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 0),\n",
       " (2, 0),\n",
       " (2, 4),\n",
       " (4, 4),\n",
       " (0, 4),\n",
       " (0, 6),\n",
       " (0, 1),\n",
       " (0, 5),\n",
       " (1, 5),\n",
       " (2, 5)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the plain game env\n",
    "As above the details of this game are described in the `boards` file. This module exists only to put the games described there into a [gym](https://github.com/openai/gym) environment, and then do some simple testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PlainGame1(gym.Env):\n",
    "    \"\"\"A one-sided game of learning and consequences\"\"\"\n",
    "    def __init__(self, maze=None, sigma=0.5, max_steps=10):\n",
    "        self.maze = maze\n",
    "        self.n = self.maze.shape[0]\n",
    "        self.max_steps = max_steps\n",
    "        \n",
    "        self.sigma = sigma\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    \n",
    "    def step(self, move):\n",
    "        if self.count > self.max_steps:\n",
    "            raise ValueError(f\"env exceeded max_steps ({self.count})\")\n",
    "\n",
    "        # Shuffle state, and generate returns\n",
    "        x, y = move\n",
    "        reward = deepcopy((self.E[x,y], self.Q[x,y]))\n",
    "        state = move\n",
    "        \n",
    "        # Values are only found once\n",
    "        self.E[x,y] = 0\n",
    "        self.Q[x,y] = 0\n",
    "        self.move_history.append(move)\n",
    "        \n",
    "        # Limit game length\n",
    "        self.count += 1\n",
    "        if self.count >= self.max_steps:\n",
    "            self.done = True\n",
    "            \n",
    "        return state, reward, self.done, {}\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        # reinit\n",
    "        self.count = 0\n",
    "        self.done = False\n",
    "        self.move_history = []\n",
    "        \n",
    "        # Generate new  \n",
    "        self.x, self.y = random_move(self.maze)\n",
    "        self.E, self.Q = plain_game(\n",
    "            self.n, sigma=self.sigma, maze=self.maze)\n",
    "        \n",
    "        return self.x, self.y\n",
    "\n",
    "    \n",
    "    def moves(self, x, y):\n",
    "        # Get all the moves then filter for moves that\n",
    "        # have already been played\n",
    "        candidates = available_moves(x, y, self.maze)\n",
    "\n",
    "        available = []\n",
    "        for a in candidates:\n",
    "            if a not in self.move_history:\n",
    "                available.append(a)\n",
    "                \n",
    "        return available\n",
    "    \n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example of random play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0) (0.3182308878266204, 0.27814523634900623) False\n",
      "(4, 1) (0.26030073020229155, 0.35724329256316883) False\n",
      "(4, 2) (0.13738590496482622, 0.24692396138345404) False\n",
      "(7, 2) (0.2874907183638171, 0.3915788684968101) False\n",
      "(7, 1) (0.07802960391072564, 0.40689833661167113) False\n",
      "(7, 3) (0.6091057523024535, 0.4552104051934325) False\n",
      "(7, 7) (0.2464934929451858, 0.9046883158305468) False\n",
      "(7, 5) (0.3447077572053019, 1.0) False\n",
      "(0, 5) (0.5985683375897632, 0.6906901950730593) False\n",
      "(0, 6) (0.44273400772512506, 0.3553407969506977) True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 2),\n",
       " (4, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (7, 2),\n",
       " (7, 1),\n",
       " (7, 3),\n",
       " (7, 7),\n",
       " (7, 5),\n",
       " (0, 5),\n",
       " (0, 6)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maze = create_maze(8, k=5, t=10)\n",
    "env = PlainGame1(maze=maze)\n",
    "\n",
    "done = False\n",
    "x, y = env.reset()\n",
    "\n",
    "moves = [(x, y)]\n",
    "while not done:\n",
    "    available = env.moves(x, y)    \n",
    "    i = np.random.randint(0, len(available))\n",
    "    x, y = available[i]\n",
    "    state, reward, done, _ = env.step((x, y))\n",
    "    moves.append((x, y))\n",
    "    \n",
    "    print(state, reward, done)\n",
    "\n",
    "moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
